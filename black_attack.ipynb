{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhiji/anaconda/envs/Fintech/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,make_scorer,confusion_matrix,roc_curve, auc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. load dataframe from cvs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/zhiji/Desktop/实习/ccts/黑产攻击识别/\"\n",
    "train = pd.read_csv(path + \"atec_anti_fraud_train.csv\")\n",
    "test = pd.read_csv(path + \"atec_anti_fraud_test_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 2. pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990006\n"
     ]
    }
   ],
   "source": [
    "#there is totally 297 features\n",
    "\n",
    "train_labeled_raw = train[train.label != -1]\n",
    "# drop all nan features\n",
    "train_labeled = train_labeled_raw.fillna(0)\n",
    "print(len(train_labeled_raw))\n",
    "features = []\n",
    "for c in train_labeled.columns:\n",
    "    if c[0] == 'f':\n",
    "        features.append(c)\n",
    "x = train_labeled[features]\n",
    "y = train_labeled.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fit machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svm_distribution(label, classnum):\n",
    "  if (classnum == 2):\n",
    "    z, t = ZeroTwoFrequency(label)\n",
    "    return 'Up：' + str(z) + ' Down：' + str(t)\n",
    "  if (classnum == 3):\n",
    "    z, o, t = ZeroOneTwoFrequency(label)\n",
    "    return 'Up：' + str(z) + ' Flat: ' + str(o) + ' Down：' + str(t)\n",
    "def get_stat_ocSVM(X, y,start_index, end_index, tuned_parameters, split = 0.8):\n",
    "    X = X[start_index:end_index]\n",
    "    y = y[start_index : end_index]\n",
    "    a_train = []\n",
    "    a_test =  []\n",
    "    classnum = 2\n",
    "    #get cleaned technical indicators\n",
    "    edge = np.int(split*len(y))\n",
    "    X_train, X_test, y_train, y_test = X[:edge], X[edge:],y[:edge],y[edge:]\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_nomalized = scaler.transform(X_train)\n",
    "    X_test_nomalized = scaler.transform(X_test)\n",
    "\n",
    "    clf = GridSearchCV(OneClassSVM(), tuned_parameters, cv = 5,\n",
    "                  scoring = 'accuracy')\n",
    "    clf.fit(X_train_nomalized, y_train)\n",
    "    prediction_train = 0.5*(clf.predict(X_train_nomalized) + 1)\n",
    "    prediction_test = 0.5*(clf.predict(X_test_nomalized) + 1)\n",
    "    cm_train = confusion_matrix(y_train, prediction_train)\n",
    "    cm_test = confusion_matrix(y_test, prediction_test)\n",
    "    print(cm_train)\n",
    "    print(cm_test)\n",
    "    print(\"2 classes prediction: \", prediction_train, prediction_test)\n",
    "    a_train.append(accuracy_score(y_train, prediction_train))\n",
    "    a_test.append(accuracy_score(y_test, prediction_test))\n",
    "#     ba_train.append(black_accuracy(y_train, prediction_train))\n",
    "#     ba_test.append(black_accuracy(y_test, prediction_test))\n",
    "    return pd.DataFrame({\n",
    "        'confusion matrix train': cm_train,\n",
    "        'confusion matrix test': cm_test\n",
    "    },index = range(end_index - start_index))\n",
    "\n",
    "def get_stat_SVM(X, y, tuned_parameters, split = 0.8):\n",
    "    d_test, d_train = [], []\n",
    "    a_train = []\n",
    "    a_test =  []\n",
    "    classnum = 2\n",
    "    #get cleaned technical indicators\n",
    "#     X, y = get_dataframe(name, iwl, fh, start_date, end_date,freq, classnum = classnum, method = 'SVM')\n",
    "    edge = np.int(split*len(y))\n",
    "    X_train, X_test, y_train, y_test = X[:edge], X[edge:],y[:edge],y[edge:]\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_nomalized = scaler.transform(X_train)\n",
    "    X_test_nomalized = scaler.transform(X_test)\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv = 5,\n",
    "                  scoring = 'accuracy')\n",
    "    clf.fit(X_train_nomalized, y_train)\n",
    "    prediction_train = clf.predict(X_train_nomalized)\n",
    "    prediction_test = clf.predict(X_test_nomalized)\n",
    "    print(\"2 classes prediction: \", prediction_train, prediction_test)\n",
    "    a_train.append(accuracy_score(y_train, prediction_train))\n",
    "    a_test.append(accuracy_score(y_test, prediction_test))\n",
    "#     z_train, t_train = ZeroTwoFrequency(y_train)\n",
    "#     z_test, t_test = ZeroTwoFrequency(y_test)\n",
    "\n",
    "    d_train.append(svm_distribution(y_train, classnum))\n",
    "    d_test.append(svm_distribution(y_test, classnum))\n",
    "\n",
    "    return pd.DataFrame({\n",
    "      '训练分布':d_train,\n",
    "      '测试分布':d_test,\n",
    "      '训练精度SVM': a_train,\n",
    "      '测试精度SVM': a_test\n",
    "    },index = idx)\n",
    "def get_onehotcode(Y):\n",
    "    array = np.array(Y)\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(np.array_split(array, len(array)))\n",
    "    one_hot_code = enc.transform(np.array_split(array, len(array))).toarray()\n",
    "    return one_hot_code\n",
    "    \n",
    "def get_stat_ANN(X, y,start_index, end_index, bs, epochs, neuron_num, split = 0.8, verbose = False):\n",
    "    X = X[start_index : end_index]\n",
    "    y = y[start_index : end_index]\n",
    "    if not 1 in y:\n",
    "        raise error(\"there is only one class should be two, please enlarge the input range\")\n",
    "    y = get_onehotcode(y)\n",
    "    classnum = neuron_num[-1]\n",
    "    d_test, d_train = [], []\n",
    "    a_train = []\n",
    "    a_test = []\n",
    "    ba_train, ba_test = [], []\n",
    "    edge = np.int(split*len(y))\n",
    "    train_X, test_X, train_y, test_y = X[:edge], X[edge:],y[:edge],y[edge:]\n",
    "    scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "    X_train_nomalized = scaler.transform(train_X)\n",
    "    X_test_nomalized = scaler.transform(test_X)\n",
    "\n",
    "\n",
    "    layer_num = len(neuron_num)\n",
    "    nx = neuron_num[0]\n",
    "    ny = neuron_num[layer_num - 1]\n",
    "    weights, biases = {}, {}\n",
    "    #get nomalized train and test set\n",
    "\n",
    "\n",
    "    x = tf.placeholder('float32',[None, nx])\n",
    "    y = tf.placeholder('float32',[None, ny])\n",
    "    layer_l = x\n",
    "    for l in range(layer_num - 2):\n",
    "        input_num = neuron_num[l]\n",
    "        hidden_num = neuron_num[l + 1]\n",
    "        weights['w' + str(l+1)] = tf.Variable(tf.random_normal([input_num, hidden_num]))\n",
    "        biases['b' + str(l+1)] = tf.Variable(tf.random_normal([hidden_num]))\n",
    "        #       layer_l = tf.layers.dense(layer_l, hudden_num, activation = tf.nn.relu)\n",
    "        layer_l = tf.nn.relu(tf.add(tf.matmul(layer_l, weights['w' + str(l+1)]), biases['b' + str(l+1)]))\n",
    "\n",
    "    weights['out'] = tf.Variable(tf.random_normal([hidden_num, ny]))\n",
    "    biases['out'] = tf.Variable(tf.random_normal([ny]))\n",
    "    prediction = tf.nn.softmax(tf.matmul(layer_l, weights['out']) + biases['out'])\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "#     d_train.append(nn_distribution(train_y))\n",
    "#     d_test.append(nn_distribution(test_y))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        losses, epoches = [],[]\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss=0\n",
    "            i=0\n",
    "            while i < len(X_train_nomalized):\n",
    "                start = i\n",
    "                end = i + bs\n",
    "                batch_x = np.array(X_train_nomalized[start:end])\n",
    "                batch_y = np.array(train_y[start:end])\n",
    "\n",
    "                _,c = sess.run([optimizer,cost] , feed_dict = {x: batch_x , y : batch_y})\n",
    "                if verbose:\n",
    "                    epoch_loss+= c\n",
    "                i+= bs\n",
    "            if (verbose) :\n",
    "                  if (epoch % 1000 == 0):\n",
    "                        print(\"Epoch\",epoch , 'completed out of ' ,epochs, ' loss: ', epoch_loss )\n",
    "                  losses.append(epoch_loss)\n",
    "                  epoches.append(epoch)\n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        print(\"prediction: \",tf.argmax(prediction,1).eval({x:X_test_nomalized}))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "\n",
    "        a_test.append(accuracy.eval({x:X_test_nomalized , y: test_y}))\n",
    "        a_train.append(accuracy.eval({x:X_train_nomalized , y: train_y}))\n",
    "        ba_train.append(black_accuracy(tf.argmax(prediction,1).eval({x:X_train_nomalized}), train_y))\n",
    "        ba_test.append(black_accuracy(tf.argmax(prediction,1).eval({x:X_test_nomalized}), test_y))\n",
    "    return pd.DataFrame({\n",
    "    '训练预测攻击精度':ba_train,\n",
    "    '测试预测攻击精度':ba_test,\n",
    "    '训练精度ANN': a_train,\n",
    "    '测试精度ANN': a_test\n",
    "    })\n",
    "def black_accuracy(pred, label):\n",
    "    length = len(pred)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(length):\n",
    "        if pred[i] == 1 or label[i] == 1:\n",
    "            total += 1\n",
    "            if (pred[i] == label[i]):\n",
    "                correct += 1\n",
    "    return correct/total\n",
    "def black_detection(X, y,start_index, end_index, tuned_parameters, split = 0.8):\n",
    "    X = X[start_index : end_index]\n",
    "    y = y[start_index : end_index]\n",
    "    classnum = 2\n",
    "    \n",
    "    edge = np.int(split*len(y))\n",
    "    X_train, X_test, y_train, y_test = X[:edge], X[edge:],y[:edge],y[edge:]\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_nomalized = scaler.transform(X_train)\n",
    "    X_test_nomalized = scaler.transform(X_test)\n",
    "    clf = GridSearchCV( OneClassSVM(), tuned_parameters, cv = 5,\n",
    "                  scoring = 'accuracy')\n",
    "    clf.fit(X_train_nomalized, y_train)\n",
    "#     y_score = f.decision_function(X_test)\n",
    "    prediction_train = -0.5*clf.predict(X_train_nomalized) + 0.5\n",
    "    prediction_test = -0.5*clf.predict(X_test_nomalized) + 0.5\n",
    "    print(prediction_test)\n",
    "#     cm_train = confusion_matrix(y_train, prediction_train)\n",
    "#     cm_test = confusion_matrix(y_test, prediction_test)\n",
    "#     print(cm_train)\n",
    "#     print(cm_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prediction_test)\n",
    "    print(fpr, tpr)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % (roc_auc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.12080537  1.        ] [ 0.   0.5  1. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gammas, Cs = [], []\n",
    "for a in np.r_[-15: 4][::2]:\n",
    "    gamma = pow(float(2), a)\n",
    "    gammas.append(gamma)\n",
    "for b in np.r_[-5: 16][::2]:\n",
    "    c = pow(float(2), b)\n",
    "    Cs.append(c)\n",
    "# Set the parameters by cross-validation  \n",
    "tuned_parameters = {'kernel': ['rbf'], 'gamma': gammas,  'C': Cs}\n",
    "tuned_parameters_oc = {'kernel': ['rbf'],'nu':[0.1,0.5], 'gamma': gammas}\n",
    "black_detection(x, y,0,3000, tuned_parameters_oc, split = 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-35eae1c0b627>:94: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0 completed out of  5000  loss:  1.05576252937\n",
      "Epoch 1000 completed out of  5000  loss:  1.05576252937\n",
      "Epoch 2000 completed out of  5000  loss:  1.05576252937\n",
      "Epoch 3000 completed out of  5000  loss:  1.05576252937\n",
      "Epoch 4000 completed out of  5000  loss:  1.05576252937\n",
      "prediction:  [1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1f437a237f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mneuron_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m297\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m297\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_stat_ANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuron_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-35eae1c0b627>\u001b[0m in \u001b[0;36mget_stat_ANN\u001b[0;34m(X, y, start_index, end_index, bs, epochs, neuron_num, split, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0ma_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test_nomalized\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0ma_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train_nomalized\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mba_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblack_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train_nomalized\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mba_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblack_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test_nomalized\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     return pd.DataFrame({\n",
      "\u001b[0;32m<ipython-input-25-35eae1c0b627>\u001b[0m in \u001b[0;36mblack_accuracy\u001b[0;34m(pred, label)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "neuron_num = [297, 500, 297, 100, 50,10, 2]\n",
    "bs = 4096\n",
    "get_stat_ANN(x, y,0,500, bs, epochs, neuron_num, split = 0.8, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ann(inputs,bs, epochs, neuron_num,verbose = False ):\n",
    "    layer_num = len(neuron_num)\n",
    "    nx = neuron_num[0]\n",
    "    ny = neuron_num[layer_num - 1]\n",
    "    weights, biases = {}, {}\n",
    "    x = tf.placeholder('float32',[None, nx])\n",
    "    y = tf.placeholder('float32',[None, ny])\n",
    "    layer_l = x\n",
    "    for l in range(layer_num - 2):\n",
    "        input_num = neuron_num[l]\n",
    "        hidden_num = neuron_num[l + 1]\n",
    "        weights['h' + str(l+1)] = tf.Variable(tf.random_normal([input_num, hidden_num]))\n",
    "        biases['b' + str(l+1)] = tf.Variable(tf.random_normal([hidden_num]))\n",
    "\n",
    "        layer_l = tf.nn.relu(tf.add(tf.matmul(layer_l, weights['h' + str(l+1)]), biases['b' + str(l+1)]))\n",
    "\n",
    "    weights['out'] = tf.Variable(tf.random_normal([hidden_num, ny]))\n",
    "    biases['out'] = tf.Variable(tf.random_normal([ny]))\n",
    "    prediction = tf.nn.softmax(tf.matmul(layer_l, weights['out']) + biases['out'])\n",
    "    tf.add_to_collection('pred', y)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        losses, epoches = [],[]\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss=0\n",
    "            i=0\n",
    "            while i < len(X_nomalized):\n",
    "                start = i\n",
    "                end = i + bs\n",
    "                batch_x = np.array(X_nomalized[start:end])\n",
    "                batch_y = np.array(Y[start:end])\n",
    "\n",
    "                _,c = sess.run([optimizer,cost] , feed_dict = {x: batch_x , y : batch_y})\n",
    "                if verbose:\n",
    "                    epoch_loss+= c\n",
    "                i+= bs\n",
    "            if (verbose) :\n",
    "                if (epoch % 1000 == 0):\n",
    "                    print(\"Epoch\",epoch , 'completed out of ' ,epochs, ' loss: ', epoch_loss )\n",
    "                losses.append(epoch_loss)\n",
    "                epoches.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8',\n",
       "       ...\n",
       "       'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296',\n",
       "       'f297'],\n",
       "      dtype='object', length=299)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_model_ANN(iwl, fh, name, bs, epochs, neuron_num, start_date, end_date,freq, verbose = False):\n",
    "  classnum = neuron_num[-1]\n",
    "  X, Y = get_dataframe(name, iwl, fh, start_date, end_date, freq, classnum = classnum, method = 'ANN')\n",
    "  scaler = preprocessing.StandardScaler().fit(X)\n",
    "  X_nomalized = scaler.transform(X)\n",
    "\n",
    "  layer_num = len(neuron_num)\n",
    "  nx = neuron_num[0]\n",
    "  ny = neuron_num[layer_num - 1]\n",
    "  weights, biases = {}, {}\n",
    "  #get nomalized train and test set\n",
    "\n",
    "\n",
    "  x = tf.placeholder('float32',[None, nx])\n",
    "  y = tf.placeholder('float32',[None, ny])\n",
    "  layer_l = x\n",
    "  for l in range(layer_num - 2):\n",
    "    input_num = neuron_num[l]\n",
    "    hidden_num = neuron_num[l + 1]\n",
    "    weights['h' + str(l+1)] = tf.Variable(tf.random_normal([input_num, hidden_num]))\n",
    "    biases['b' + str(l+1)] = tf.Variable(tf.random_normal([hidden_num]))\n",
    "\n",
    "    layer_l = tf.nn.relu(tf.add(tf.matmul(layer_l, weights['h' + str(l+1)]), biases['b' + str(l+1)]))\n",
    "\n",
    "  weights['out'] = tf.Variable(tf.random_normal([hidden_num, ny]))\n",
    "  biases['out'] = tf.Variable(tf.random_normal([ny]))\n",
    "  prediction = tf.nn.softmax(tf.matmul(layer_l, weights['out']) + biases['out'])\n",
    "  tf.add_to_collection('pred', y)\n",
    "\n",
    "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "      sess.run(tf.initialize_all_variables())\n",
    "      losses, epoches = [],[]\n",
    "      for epoch in range(epochs):\n",
    "          epoch_loss=0\n",
    "          i=0\n",
    "          while i < len(X_nomalized):\n",
    "              start = i\n",
    "              end = i + bs\n",
    "              batch_x = np.array(X_nomalized[start:end])\n",
    "              batch_y = np.array(Y[start:end])\n",
    "\n",
    "              _,c = sess.run([optimizer,cost] , feed_dict = {x: batch_x , y : batch_y})\n",
    "              if verbose:\n",
    "                  epoch_loss+= c\n",
    "              i+= bs\n",
    "          if (verbose) :\n",
    "                if (epoch % 1000 == 0):\n",
    "                  print(\"Epoch\",epoch , 'completed out of ' ,epochs, ' loss: ', epoch_loss )\n",
    "                losses.append(epoch_loss)\n",
    "                epoches.append(epoch)\n",
    "      path = \"./\"\n",
    "      model_name = \"ann\" + str(classnum) +\".ckpt\"\n",
    "      print(\"model name is : \" + model_name)\n",
    "      saver.save(sess, path + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python(Fintech)",
   "language": "python",
   "name": "fintech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
