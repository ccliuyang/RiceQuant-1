{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rqdatac as rq\n",
    "from rqdatac import *\n",
    "rq.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/dell/anaconda3/envs/Fintech/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/dell/anaconda3/envs/Fintech/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout,Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD,Adam,Adadelta\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf():\n",
    "    param_test1 = {'n_estimators':[10, 30, 50, 70]}\n",
    "    clf = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "    return clf\n",
    "def ann():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31, activation = 'relu', input_shape = (31, )))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation = 'relu'))\n",
    "    model.add(Dense(2, activation = 'softmax', bias_regularizer=regularizers.l1(0.00001)))\n",
    "    adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer = adadelta, metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "def panel_append(p):\n",
    "    result = []\n",
    "    r = np.concatenate((np.r_[1:21],np.r_[40:241:20]))\n",
    "    for m in r:\n",
    "        rt = (p/p.shift(m)) - 1\n",
    "        result.append(rt)\n",
    "    return list(np.array(result).T)\n",
    "\n",
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(25, return_sequences = False,\n",
    "                   input_shape=(240, 1)))  # returns a sequence of vectors of dimension 32\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy'])\n",
    "    return model\n",
    "def sandlize(erd):\n",
    "    return np.reshape(erd,(erd.shape[0], erd.shape[1], 1))\n",
    "def lstm_append(p):\n",
    "    result = []\n",
    "    r = np.r_[1:241]\n",
    "    for m in r:\n",
    "        rt = (p/p.shift(m)) - 1\n",
    "        result.append(rt)\n",
    "    return list(np.array(result).T)\n",
    "def get_return(model, start_date = '20050104', end_date ='20180709', index_name = '399001.XSHE',cost = 0, k = 5):\n",
    "    valid_inputs =  ['lstm','rf','log','ann']\n",
    "    if not model in valid_inputs:\n",
    "        print('illegal input, inputs should be in', valid_inputs)\n",
    "        return\n",
    "    if (type(model) != str):\n",
    "        print('wrong input type, model should be string.')\n",
    "    else:\n",
    "        if model == 'lstm':\n",
    "            returns, dates = get_return_lstm(start_date, end_date, index_name, cost, k)\n",
    "        if model == 'rf':\n",
    "            returns, dates = get_return_rf(start_date, end_date, index_name, cost, k)\n",
    "        if model == 'log':\n",
    "            returns, dates = get_return_log(start_date, end_date, index_name, cost, k)\n",
    "        if model == 'ann':\n",
    "            returns, dates = get_return_ann(start_date, end_date, index_name, cost, k)\n",
    "    return returns, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_return_lstm(start_date, end_date, index_name = '399001.XSHE', cost = 0,k = 5):\n",
    "    index = []\n",
    "    returns, dates = [],[]\n",
    "    ics = index_components(index_name)\n",
    "    ps = get_price(ics, start_date, end_date,frequency = '1d')['close']\n",
    "    \n",
    "    for i in np.r_[0:len(ps.index)-1000:250]:\n",
    "# Get close prices\n",
    "        p = ps[i:i+1000].dropna(axis = 'columns', how = 'any')\n",
    "        ics_new = p.columns\n",
    "        if (len(ics_new) < k*2):\n",
    "            print(len(ics_new))\n",
    "            continue\n",
    "        rt = (p - p.shift(1))/p\n",
    "        med = rt.median(axis = 1)\n",
    "        x_all = p.apply(lambda z : lstm_append(z))\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for ic in ics_new:\n",
    "            x = x_all[ic]\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_train += list(x)[241:749]\n",
    "            y_train += list(y)[242:750]\n",
    "        y_train_oh = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "        if (len(X_train) != len(y_train)):\n",
    "            print('i:',i)\n",
    "            continue\n",
    "        model_lstm = lstm()\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=0, mode='min')\n",
    "        model_lstm.fit(sandlize(np.array(X_train)), y_train_oh,epochs = 15,callbacks=[early_stopping])\n",
    "        pred_train = model_lstm.predict(sandlize(np.array(X_train)))\n",
    "        acc_train = model_lstm.evaluate(sandlize(np.array(X_train)), pred_train, verbose = 0)\n",
    "        print()\n",
    "        dic = pd.DataFrame()\n",
    "        for ic in ics_new:\n",
    "\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_test = list(x_all[ic])[750: -1]   \n",
    "            proba_test = model_lstm.predict_proba(sandlize(np.array(X_test)))\n",
    "            dic[ic] = np.array(proba_test)[:,1]\n",
    "        if (len(dic.index) < 248):\n",
    "            print(len(dic.index))\n",
    "            continue\n",
    "        for t in np.r_[750:999]:\n",
    "        \n",
    "            top_ks = dic.sort_values(by = dic.index[t-750], axis = 'columns', ascending = False).columns[:k]\n",
    "            for ic in top_ks:\n",
    "                this_profit = rt[ic][t+1]\n",
    "            returns.append(this_profit/k)\n",
    "            dates.append(ps.index[i+t])\n",
    "    return returns, dates\n",
    "\n",
    "\n",
    "def get_return_rf(start_date, end_date, index_name = '399001.XSHE', cost = 0,k = 5):\n",
    "    profit_all, profit_everyday, accuracy_train = [],[],[]\n",
    "    index = []\n",
    "    returns,dates = [],[]\n",
    "    ics = index_components(index_name)\n",
    "    ps = get_price(ics, start_date, end_date,frequency = '1d')['close']\n",
    "    \n",
    "    for i in np.r_[0:len(ps.index)-1000:250]:\n",
    "        print(i)\n",
    "# Get close prices\n",
    "        p = ps[i:i+1000].dropna(axis = 'columns', how = 'any')\n",
    "        ics_new = p.columns\n",
    "        if (len(ics_new) < k*2):\n",
    "            print(len(ics_new))\n",
    "            continue\n",
    "        rt = (p - p.shift(1))/p\n",
    "        med = rt.median(axis = 1)\n",
    "        x_all = p.apply(lambda z : panel_append(z))\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for ic in ics_new:\n",
    "            x = x_all[ic]\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_train += list(x)[241:749]\n",
    "            y_train += list(y)[242:750]\n",
    "        if (len(X_train) != len(y_train)):\n",
    "            print('i:',i)\n",
    "            continue\n",
    "        model_rf = rf()\n",
    "        model_rf.fit(X_train, y_train)\n",
    "        pred_train = model_rf.predict(X_train)\n",
    "        acc_train = accuracy_score(y_train, pred_train)\n",
    "        dic = pd.DataFrame()\n",
    "        for ic in ics_new:\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_test = list(x_all[ic])[750: -1]   \n",
    "            proba_test = model_rf.predict_proba(X_test)\n",
    "            dic[ic] = np.array(proba_test)[:,1]\n",
    "        if (len(dic.index) < 248):\n",
    "            continue\n",
    "        for t in np.r_[750:999]:\n",
    "            top_ks = dic.sort_values(by = dic.index[t-750], axis = 'columns', ascending = False).columns[:k]\n",
    "            this_profit = 0\n",
    "            for ic in top_ks:\n",
    "                this_profit += rt[ic][t+1]\n",
    "            returns.append(this_profit/k)\n",
    "            dates.append(ps.index[i+t])\n",
    "            \n",
    "    return returns, dates\n",
    "\n",
    "def get_return_log(start_date, end_date, index_name = '399001.XSHE', cost = 0,k = 5):\n",
    "    profit_all, profit_everyday, accuracy_train = [],[],[]\n",
    "    index = []\n",
    "    returns,dates = [],[]\n",
    "    ics = index_components(index_name)\n",
    "    ps = get_price(ics, start_date, end_date,frequency = '1d')['close']\n",
    "    \n",
    "    for i in np.r_[0:len(ps.index)-1000:250]:\n",
    "# Get close prices\n",
    "        p = ps[i:i+1000].dropna(axis = 'columns', how = 'any')\n",
    "        ics_new = p.columns\n",
    "        if (len(ics_new) < k*2):\n",
    "            print(len(ics_new))\n",
    "            continue\n",
    "        rt = (p - p.shift(1))/p\n",
    "        med = rt.median(axis = 1)\n",
    "        x_all = p.apply(lambda z : panel_append(z))\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for ic in ics_new:\n",
    "            x = x_all[ic]\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_train += list(x)[241:749]\n",
    "            y_train += list(y)[242:750]\n",
    "        if (len(X_train) != len(y_train)):\n",
    "            print('i:',i)\n",
    "            continue\n",
    "        model_log = LogisticRegression()\n",
    "        model_log.fit(X_train, y_train)\n",
    "        pred_train = model_log.predict(X_train)\n",
    "        acc_train = accuracy_score(y_train, pred_train)\n",
    "        dic = pd.DataFrame()\n",
    "        for ic in ics_new:\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_test = list(x_all[ic])[750: -1]   \n",
    "            proba_test = model_log.predict_proba(X_test)\n",
    "            dic[ic] = np.array(proba_test)[:,1]\n",
    "        if (len(dic.index) < 248):\n",
    "            continue\n",
    "        for t in np.r_[750:999]:\n",
    "            top_ks = dic.sort_values(by = dic.index[t-750], axis = 'columns', ascending = False).columns[:k]\n",
    "            this_profit = 0\n",
    "            for ic in top_ks:\n",
    "                this_profit += rt[ic][t+1]\n",
    "#             print(this_profit/k, list(ps.index)[i+t])\n",
    "            returns.append(this_profit/k)\n",
    "            dates.append(ps.index[i+t])\n",
    "            \n",
    "    return returns, dates\n",
    "\n",
    "def get_return_ann(start_date, end_date, index_name = '399001.XSHE' , cost = 0,k = 5):\n",
    "    returns, dates= [],[]\n",
    "    index = []\n",
    "    ics = index_components(index_name)\n",
    "    ps = get_price(ics, start_date, end_date,frequency = '1d')['close']\n",
    "    \n",
    "    for i in np.r_[0:len(ps.index)-1000:250]:\n",
    "# Get close prices\n",
    "        p = ps[i:i+1000].dropna(axis = 'columns', how = 'any')\n",
    "        ics_new = p.columns\n",
    "        print(len(ics_new))\n",
    "        if (len(ics_new) < k*2):\n",
    "            print(len(ics_new))\n",
    "            continue\n",
    "        rt = (p - p.shift(1))/p\n",
    "        med = rt.median(axis = 1)\n",
    "        x_all = p.apply(lambda z : panel_append(z))\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for ic in ics_new:\n",
    "            x = x_all[ic]\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_train += list(x)[241:749]\n",
    "            y_train += list(y)[242:750]\n",
    "        y_train_oh = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "        if (len(X_train) != len(y_train)):\n",
    "            print('i:',i)\n",
    "            continue\n",
    "        model_ann = ann()\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\n",
    "        model_ann.fit(np.array(X_train), y_train_oh,epochs = 80, callbacks = [early_stopping])\n",
    "        pred_train = model_ann.predict(np.array(X_train))\n",
    "        acc_train = model_ann.evaluate(np.array(X_train), pred_train)\n",
    "        dic = pd.DataFrame()\n",
    "        for ic in ics_new:\n",
    "            y = (rt[ic] > med) * 1\n",
    "            X_test = list(x_all[ic])[750: -1]   \n",
    "            proba_test = model_ann.predict(np.array(X_test))\n",
    "            dic[ic] = np.array(proba_test)[:,1]\n",
    "        if (len(dic.index) < 248):\n",
    "            print(len(dic.index))\n",
    "            continue\n",
    "        for t in np.r_[750:999]:\n",
    "        \n",
    "            top_ks = dic.sort_values(by = dic.index[t-750], axis = 'columns', ascending = False).columns[:k]\n",
    "            for ic in top_ks:\n",
    "                this_profit = rt[ic][t+1]/k\n",
    "            returns.append(this_profit)\n",
    "            dates.append(ps.index[i+t])\n",
    "    return returns, dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n"
     ]
    }
   ],
   "source": [
    "returns, dates = get_return('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "returns_log, dates_log = get_return('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "Epoch 1/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5128     \n",
      "Epoch 2/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6926 - binary_accuracy: 0.5150     \n",
      "Epoch 3/80\n",
      "93980/93980 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5131     \n",
      "Epoch 4/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5147     \n",
      "Epoch 5/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5142     \n",
      "Epoch 6/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6922 - binary_accuracy: 0.5140     \n",
      "Epoch 7/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5146     \n",
      "Epoch 8/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5147     \n",
      "Epoch 9/80\n",
      "93980/93980 [==============================] - 6s - loss: 0.6921 - binary_accuracy: 0.5130     \n",
      "Epoch 10/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5136     \n",
      "Epoch 11/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5144     \n",
      "Epoch 12/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5128     \n",
      "Epoch 13/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5156     \n",
      "Epoch 14/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5145     \n",
      "Epoch 15/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6917 - binary_accuracy: 0.5140     \n",
      "Epoch 16/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5146     \n",
      "Epoch 17/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5146     \n",
      "Epoch 18/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5155     \n",
      "Epoch 19/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5141     \n",
      "Epoch 20/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5158     \n",
      "Epoch 21/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6916 - binary_accuracy: 0.5162     \n",
      "Epoch 22/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5144     \n",
      "Epoch 23/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5151     \n",
      "Epoch 24/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6917 - binary_accuracy: 0.5148     \n",
      "Epoch 25/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6914 - binary_accuracy: 0.5131     \n",
      "Epoch 26/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5158     \n",
      "Epoch 27/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6916 - binary_accuracy: 0.5135     \n",
      "Epoch 28/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5140     \n",
      "Epoch 29/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5150     \n",
      "Epoch 30/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6916 - binary_accuracy: 0.5170     \n",
      "Epoch 31/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6915 - binary_accuracy: 0.5156     \n",
      "Epoch 32/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5139     \n",
      "Epoch 33/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6917 - binary_accuracy: 0.5161     \n",
      "Epoch 34/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6914 - binary_accuracy: 0.5167     \n",
      "Epoch 35/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6916 - binary_accuracy: 0.5139     \n",
      "Epoch 36/80\n",
      "93980/93980 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5149     \n",
      "93792/93980 [============================>.] - ETA: 0s192\n",
      "Epoch 1/80\n",
      "97536/97536 [==============================] - 7s - loss: 0.6937 - binary_accuracy: 0.5060     \n",
      "Epoch 2/80\n",
      "97536/97536 [==============================] - 7s - loss: 0.6933 - binary_accuracy: 0.5037     \n",
      "Epoch 3/80\n",
      "97536/97536 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5053     \n",
      "Epoch 4/80\n",
      "97536/97536 [==============================] - 7s - loss: 0.6931 - binary_accuracy: 0.5067     \n",
      "Epoch 5/80\n",
      "97536/97536 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5036     \n",
      "Epoch 6/80\n",
      "97536/97536 [==============================] - 6s - loss: 0.6931 - binary_accuracy: 0.5062     \n",
      "Epoch 7/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6931 - binary_accuracy: 0.5062     \n",
      "Epoch 8/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5068     \n",
      "Epoch 9/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5067     \n",
      "Epoch 10/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5066     \n",
      "Epoch 11/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6929 - binary_accuracy: 0.5072     \n",
      "Epoch 12/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5088     \n",
      "Epoch 13/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5075     \n",
      "Epoch 14/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6929 - binary_accuracy: 0.5067     \n",
      "Epoch 15/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5056     \n",
      "Epoch 16/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5081     \n",
      "Epoch 17/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5082     \n",
      "Epoch 18/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5102     \n",
      "Epoch 19/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6931 - binary_accuracy: 0.5074     \n",
      "Epoch 20/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5072     \n",
      "Epoch 21/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5078     \n",
      "Epoch 22/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5093     \n",
      "Epoch 23/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5091     \n",
      "Epoch 24/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6928 - binary_accuracy: 0.5109     \n",
      "Epoch 25/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5100     \n",
      "Epoch 26/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5120     \n",
      "Epoch 27/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5106     \n",
      "Epoch 28/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5125     \n",
      "Epoch 29/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5103     \n",
      "Epoch 30/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5093     \n",
      "Epoch 31/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5130     \n",
      "Epoch 32/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5118     \n",
      "Epoch 33/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5122     \n",
      "Epoch 34/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5123     \n",
      "Epoch 35/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5123     \n",
      "Epoch 36/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5114     \n",
      "Epoch 37/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5135     \n",
      "Epoch 38/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5137     \n",
      "Epoch 39/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5153     \n",
      "Epoch 40/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5124     \n",
      "Epoch 41/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5137     \n",
      "Epoch 42/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5136     \n",
      "Epoch 43/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5147     \n",
      "Epoch 44/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5146     \n",
      "Epoch 45/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6927 - binary_accuracy: 0.5128     \n",
      "Epoch 46/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5134     \n",
      "Epoch 47/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5160     \n",
      "Epoch 48/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5149     \n",
      "Epoch 49/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5156     \n",
      "Epoch 50/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5196     \n",
      "Epoch 51/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5182     \n",
      "Epoch 52/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5163     \n",
      "Epoch 53/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5170     \n",
      "Epoch 54/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5153     \n",
      "Epoch 55/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5185     \n",
      "Epoch 56/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5163     \n",
      "Epoch 57/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5179     \n",
      "Epoch 58/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5202     \n",
      "Epoch 59/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5191     \n",
      "Epoch 60/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5202     \n",
      "Epoch 61/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5190     \n",
      "Epoch 62/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5151     \n",
      "Epoch 63/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5190     \n",
      "Epoch 64/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5203     \n",
      "Epoch 65/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5204     \n",
      "Epoch 66/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6918 - binary_accuracy: 0.5185     \n",
      "Epoch 67/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6916 - binary_accuracy: 0.5195     \n",
      "Epoch 68/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6919 - binary_accuracy: 0.5193     \n",
      "Epoch 69/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5207     \n",
      "Epoch 70/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5197     \n",
      "Epoch 71/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6917 - binary_accuracy: 0.5199     \n",
      "Epoch 72/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6914 - binary_accuracy: 0.5203     \n",
      "Epoch 73/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6912 - binary_accuracy: 0.5230     \n",
      "Epoch 74/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6916 - binary_accuracy: 0.5212     \n",
      "Epoch 75/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6916 - binary_accuracy: 0.5204     \n",
      "Epoch 76/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6914 - binary_accuracy: 0.5217     \n",
      "Epoch 77/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6913 - binary_accuracy: 0.5204     \n",
      "Epoch 78/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6916 - binary_accuracy: 0.5201     \n",
      "Epoch 79/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6915 - binary_accuracy: 0.5223     \n",
      "Epoch 80/80\n",
      "97536/97536 [==============================] - 5s - loss: 0.6914 - binary_accuracy: 0.5211     \n",
      "97408/97536 [============================>.] - ETA: 0s209\n",
      "Epoch 1/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6935 - binary_accuracy: 0.5040     \n",
      "Epoch 2/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5020     \n",
      "Epoch 3/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5018     \n",
      "Epoch 4/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6931 - binary_accuracy: 0.5051     \n",
      "Epoch 5/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6931 - binary_accuracy: 0.5068     \n",
      "Epoch 6/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6930 - binary_accuracy: 0.5069     \n",
      "Epoch 7/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5065     \n",
      "Epoch 8/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6930 - binary_accuracy: 0.5074     \n",
      "Epoch 9/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6929 - binary_accuracy: 0.5086     \n",
      "Epoch 10/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6929 - binary_accuracy: 0.5083     \n",
      "Epoch 11/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6928 - binary_accuracy: 0.5088     \n",
      "Epoch 12/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5112     \n",
      "Epoch 13/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6928 - binary_accuracy: 0.5115     \n",
      "Epoch 14/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6928 - binary_accuracy: 0.5109     \n",
      "Epoch 15/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5130     \n",
      "Epoch 16/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5156     \n",
      "Epoch 17/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5156     \n",
      "Epoch 18/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5139     \n",
      "Epoch 19/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5128     \n",
      "Epoch 20/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5106     \n",
      "Epoch 21/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5145     \n",
      "Epoch 22/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5146     \n",
      "Epoch 23/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5157     \n",
      "Epoch 24/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5152     \n",
      "Epoch 25/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5140     \n",
      "Epoch 26/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5141     \n",
      "Epoch 27/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5137     \n",
      "Epoch 28/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5165     \n",
      "Epoch 29/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6924 - binary_accuracy: 0.5151     \n",
      "Epoch 30/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5167     \n",
      "Epoch 31/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5161     \n",
      "Epoch 32/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6924 - binary_accuracy: 0.5142     \n",
      "Epoch 33/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6925 - binary_accuracy: 0.5144     \n",
      "Epoch 34/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5144     \n",
      "Epoch 35/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5156     \n",
      "Epoch 36/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6926 - binary_accuracy: 0.5162     \n",
      "Epoch 37/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6925 - binary_accuracy: 0.5143     \n",
      "Epoch 38/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5181     \n",
      "Epoch 39/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6924 - binary_accuracy: 0.5176     \n",
      "Epoch 40/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6924 - binary_accuracy: 0.5159     \n",
      "Epoch 41/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5175     \n",
      "Epoch 42/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6921 - binary_accuracy: 0.5205     \n",
      "Epoch 43/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5184     \n",
      "Epoch 44/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5156     \n",
      "Epoch 45/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5147     \n",
      "Epoch 46/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5137     \n",
      "Epoch 47/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5156     \n",
      "Epoch 48/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6921 - binary_accuracy: 0.5191     \n",
      "Epoch 49/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5181     \n",
      "Epoch 50/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5182     \n",
      "Epoch 51/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5193     \n",
      "Epoch 52/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6923 - binary_accuracy: 0.5150     \n",
      "Epoch 53/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5173     \n",
      "Epoch 54/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5180     \n",
      "Epoch 55/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5185     \n",
      "Epoch 56/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5168     \n",
      "Epoch 57/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6924 - binary_accuracy: 0.5171     \n",
      "Epoch 58/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5161     \n",
      "Epoch 59/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5208     \n",
      "Epoch 60/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5176     \n",
      "Epoch 61/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6922 - binary_accuracy: 0.5181     \n",
      "Epoch 62/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6920 - binary_accuracy: 0.5204     \n",
      "Epoch 63/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5178     \n",
      "Epoch 64/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6922 - binary_accuracy: 0.5165     \n",
      "Epoch 65/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5207     \n",
      "Epoch 66/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5178     \n",
      "Epoch 67/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5171     \n",
      "Epoch 68/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5188     \n",
      "Epoch 69/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5193     \n",
      "Epoch 70/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5180     \n",
      "Epoch 71/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5193     \n",
      "Epoch 72/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5196     \n",
      "Epoch 73/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6921 - binary_accuracy: 0.5178     \n",
      "Epoch 74/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6921 - binary_accuracy: 0.5187     \n",
      "Epoch 75/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6920 - binary_accuracy: 0.5201     \n",
      "Epoch 76/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6919 - binary_accuracy: 0.5205     \n",
      "Epoch 77/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6917 - binary_accuracy: 0.5217     \n",
      "Epoch 78/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6918 - binary_accuracy: 0.5199     \n",
      "Epoch 79/80\n",
      "106172/106172 [==============================] - 5s - loss: 0.6920 - binary_accuracy: 0.5202     \n",
      "Epoch 80/80\n",
      "106172/106172 [==============================] - 6s - loss: 0.6918 - binary_accuracy: 0.5192     \n",
      "105440/106172 [============================>.] - ETA: 0s240\n",
      "Epoch 1/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6934 - binary_accuracy: 0.5027     \n",
      "Epoch 2/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5015     \n",
      "Epoch 3/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5003     \n",
      "Epoch 4/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5024     \n",
      "Epoch 5/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5017     \n",
      "Epoch 6/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5012     \n",
      "Epoch 7/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5020     \n",
      "Epoch 8/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5021     \n",
      "Epoch 9/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5028     \n",
      "Epoch 10/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6933 - binary_accuracy: 0.5027     \n",
      "Epoch 11/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5038     \n",
      "Epoch 12/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5029     \n",
      "Epoch 13/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5014     \n",
      "Epoch 14/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5022     \n",
      "Epoch 15/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5036     \n",
      "Epoch 16/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5042     \n",
      "Epoch 17/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5019     \n",
      "Epoch 18/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5004     \n",
      "Epoch 19/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5029     \n",
      "Epoch 20/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5035     \n",
      "Epoch 21/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5035     \n",
      "Epoch 22/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6932 - binary_accuracy: 0.5024     \n",
      "Epoch 23/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6933 - binary_accuracy: 0.5042     \n",
      "Epoch 24/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6932 - binary_accuracy: 0.5056     \n",
      "Epoch 25/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6931 - binary_accuracy: 0.5049     \n",
      "Epoch 26/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6929 - binary_accuracy: 0.5091     \n",
      "Epoch 27/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6930 - binary_accuracy: 0.5081     \n",
      "Epoch 28/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6929 - binary_accuracy: 0.5104     \n",
      "Epoch 29/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6927 - binary_accuracy: 0.5120     \n",
      "Epoch 30/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6926 - binary_accuracy: 0.5143     \n",
      "Epoch 31/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5169     \n",
      "Epoch 32/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6923 - binary_accuracy: 0.5177     \n",
      "Epoch 33/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5190     \n",
      "Epoch 34/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6920 - binary_accuracy: 0.5204     \n",
      "Epoch 35/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6920 - binary_accuracy: 0.5211     \n",
      "Epoch 36/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6918 - binary_accuracy: 0.5220     \n",
      "Epoch 37/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6917 - binary_accuracy: 0.5228     \n",
      "Epoch 38/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6917 - binary_accuracy: 0.5229     \n",
      "Epoch 39/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6915 - binary_accuracy: 0.5231     \n",
      "Epoch 40/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6916 - binary_accuracy: 0.5226     \n",
      "Epoch 41/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6915 - binary_accuracy: 0.5230     \n",
      "Epoch 42/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6914 - binary_accuracy: 0.5237     \n",
      "Epoch 43/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6914 - binary_accuracy: 0.5243     \n",
      "Epoch 44/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6913 - binary_accuracy: 0.5261     \n",
      "Epoch 45/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6913 - binary_accuracy: 0.5271     \n",
      "Epoch 46/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6914 - binary_accuracy: 0.5260     \n",
      "Epoch 47/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6912 - binary_accuracy: 0.5255     \n",
      "Epoch 48/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6912 - binary_accuracy: 0.5249     \n",
      "Epoch 49/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6910 - binary_accuracy: 0.5261     \n",
      "Epoch 50/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6913 - binary_accuracy: 0.5256     \n",
      "Epoch 51/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6910 - binary_accuracy: 0.5286     \n",
      "Epoch 52/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6911 - binary_accuracy: 0.5277     \n",
      "Epoch 53/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6911 - binary_accuracy: 0.5262     \n",
      "Epoch 54/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6909 - binary_accuracy: 0.5274     \n",
      "Epoch 55/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6909 - binary_accuracy: 0.5285     \n",
      "Epoch 56/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6909 - binary_accuracy: 0.5264     \n",
      "Epoch 57/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6911 - binary_accuracy: 0.5270     \n",
      "Epoch 58/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6907 - binary_accuracy: 0.5297     \n",
      "Epoch 59/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6909 - binary_accuracy: 0.5288     \n",
      "Epoch 60/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6908 - binary_accuracy: 0.5284     \n",
      "Epoch 61/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6908 - binary_accuracy: 0.5268     \n",
      "Epoch 62/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6909 - binary_accuracy: 0.5264     \n",
      "Epoch 63/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6904 - binary_accuracy: 0.5282     \n",
      "Epoch 64/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6906 - binary_accuracy: 0.5293     \n",
      "Epoch 65/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6906 - binary_accuracy: 0.5261     \n",
      "Epoch 66/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6906 - binary_accuracy: 0.5285     \n",
      "Epoch 67/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6906 - binary_accuracy: 0.5278     \n",
      "Epoch 68/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6908 - binary_accuracy: 0.5277     \n",
      "Epoch 69/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6903 - binary_accuracy: 0.5297     \n",
      "Epoch 70/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6905 - binary_accuracy: 0.5278     \n",
      "Epoch 71/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6904 - binary_accuracy: 0.5304     \n",
      "Epoch 72/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6906 - binary_accuracy: 0.5277     \n",
      "Epoch 73/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6905 - binary_accuracy: 0.5282     \n",
      "Epoch 74/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6904 - binary_accuracy: 0.5301     \n",
      "Epoch 75/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6907 - binary_accuracy: 0.5292     \n",
      "Epoch 76/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6903 - binary_accuracy: 0.5295     \n",
      "Epoch 77/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6905 - binary_accuracy: 0.5290     \n",
      "Epoch 78/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6904 - binary_accuracy: 0.5279     \n",
      "Epoch 79/80\n",
      "121920/121920 [==============================] - 6s - loss: 0.6903 - binary_accuracy: 0.5296     \n",
      "Epoch 80/80\n",
      "121920/121920 [==============================] - 7s - loss: 0.6905 - binary_accuracy: 0.5307     \n",
      "120704/121920 [============================>.] - ETA: 0s259\n",
      "Epoch 1/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6935 - binary_accuracy: 0.5064     \n",
      "Epoch 2/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6933 - binary_accuracy: 0.5053     \n",
      "Epoch 3/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6930 - binary_accuracy: 0.5060     \n",
      "Epoch 4/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6933 - binary_accuracy: 0.5040     \n",
      "Epoch 5/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6930 - binary_accuracy: 0.5083     \n",
      "Epoch 6/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6930 - binary_accuracy: 0.5089     \n",
      "Epoch 7/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6930 - binary_accuracy: 0.5041     \n",
      "Epoch 8/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6930 - binary_accuracy: 0.5068     \n",
      "Epoch 9/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6928 - binary_accuracy: 0.5086     \n",
      "Epoch 10/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6929 - binary_accuracy: 0.5111     \n",
      "Epoch 11/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5125     \n",
      "Epoch 12/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6928 - binary_accuracy: 0.5098     \n",
      "Epoch 13/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6925 - binary_accuracy: 0.5141     \n",
      "Epoch 14/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5130     \n",
      "Epoch 15/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5123     \n",
      "Epoch 16/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6926 - binary_accuracy: 0.5122     \n",
      "Epoch 17/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5132     \n",
      "Epoch 18/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5109     \n",
      "Epoch 19/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6926 - binary_accuracy: 0.5133     \n",
      "Epoch 20/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6925 - binary_accuracy: 0.5165     \n",
      "Epoch 21/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6926 - binary_accuracy: 0.5127     \n",
      "Epoch 22/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5130     \n",
      "Epoch 23/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5154     \n",
      "Epoch 24/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5146     \n",
      "Epoch 25/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5137     \n",
      "Epoch 26/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5151     \n",
      "Epoch 27/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6927 - binary_accuracy: 0.5146     \n",
      "Epoch 28/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5153     \n",
      "Epoch 29/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5167     \n",
      "Epoch 30/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5137     \n",
      "Epoch 31/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5154     \n",
      "Epoch 32/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5168     \n",
      "Epoch 33/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6925 - binary_accuracy: 0.5151     \n",
      "Epoch 34/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6924 - binary_accuracy: 0.5159     \n",
      "Epoch 35/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5177     \n",
      "Epoch 36/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5173     \n",
      "Epoch 37/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5186     \n",
      "Epoch 38/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6922 - binary_accuracy: 0.5164     \n",
      "Epoch 39/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5157     \n",
      "Epoch 40/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5179     \n",
      "Epoch 41/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5162     \n",
      "Epoch 42/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5154     \n",
      "Epoch 43/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5179     \n",
      "Epoch 44/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5169     \n",
      "Epoch 45/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5178     \n",
      "Epoch 46/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5188     \n",
      "Epoch 47/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5207     \n",
      "Epoch 48/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6922 - binary_accuracy: 0.5175     \n",
      "Epoch 49/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5178     \n",
      "Epoch 50/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5199     \n",
      "Epoch 51/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6922 - binary_accuracy: 0.5186     \n",
      "Epoch 52/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6922 - binary_accuracy: 0.5184     \n",
      "Epoch 53/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5186     \n",
      "Epoch 54/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5186     \n",
      "Epoch 55/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5189     \n",
      "Epoch 56/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5193     \n",
      "Epoch 57/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5188     \n",
      "Epoch 58/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5191     \n",
      "Epoch 59/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5200     \n",
      "Epoch 60/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5200     \n",
      "Epoch 61/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5185     \n",
      "Epoch 62/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5189     \n",
      "Epoch 63/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5199     \n",
      "Epoch 64/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5187     \n",
      "Epoch 65/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5192     \n",
      "Epoch 66/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5202     \n",
      "Epoch 67/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5176     \n",
      "Epoch 68/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5179     \n",
      "Epoch 69/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5196     \n",
      "Epoch 70/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6920 - binary_accuracy: 0.5191     \n",
      "Epoch 71/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5182     \n",
      "Epoch 72/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5199     \n",
      "Epoch 73/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5200     \n",
      "Epoch 74/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6921 - binary_accuracy: 0.5193     \n",
      "Epoch 75/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6917 - binary_accuracy: 0.5193     \n",
      "Epoch 76/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6916 - binary_accuracy: 0.5209     \n",
      "Epoch 77/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6918 - binary_accuracy: 0.5216     \n",
      "Epoch 78/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6919 - binary_accuracy: 0.5215     \n",
      "Epoch 79/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6917 - binary_accuracy: 0.5202     \n",
      "Epoch 80/80\n",
      "131572/131572 [==============================] - 7s - loss: 0.6923 - binary_accuracy: 0.5199     \n",
      "130496/131572 [============================>.] - ETA: 0s304\n",
      "Epoch 1/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6938 - binary_accuracy: 0.5061     \n",
      "Epoch 2/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6935 - binary_accuracy: 0.5058     \n",
      "Epoch 3/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6933 - binary_accuracy: 0.5070     \n",
      "Epoch 4/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6930 - binary_accuracy: 0.5116     \n",
      "Epoch 5/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6931 - binary_accuracy: 0.5070     \n",
      "Epoch 6/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6930 - binary_accuracy: 0.5081     \n",
      "Epoch 7/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5125     \n",
      "Epoch 8/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6928 - binary_accuracy: 0.5112     \n",
      "Epoch 9/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6929 - binary_accuracy: 0.5114     \n",
      "Epoch 10/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5117     \n",
      "Epoch 11/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6929 - binary_accuracy: 0.5128     \n",
      "Epoch 12/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5122     \n",
      "Epoch 13/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6930 - binary_accuracy: 0.5127     \n",
      "Epoch 14/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6927 - binary_accuracy: 0.5140     \n",
      "Epoch 15/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6926 - binary_accuracy: 0.5149     \n",
      "Epoch 16/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6927 - binary_accuracy: 0.5145     \n",
      "Epoch 17/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6927 - binary_accuracy: 0.5138     \n",
      "Epoch 18/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5165     \n",
      "Epoch 19/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5143     \n",
      "Epoch 20/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5133     \n",
      "Epoch 21/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6926 - binary_accuracy: 0.5149     \n",
      "Epoch 22/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6926 - binary_accuracy: 0.5114     \n",
      "Epoch 23/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5161     \n",
      "Epoch 24/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5167     \n",
      "Epoch 25/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6924 - binary_accuracy: 0.5168     \n",
      "Epoch 26/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6929 - binary_accuracy: 0.5162     \n",
      "Epoch 27/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5142     \n",
      "Epoch 28/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6928 - binary_accuracy: 0.5163     \n",
      "Epoch 29/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6926 - binary_accuracy: 0.5179     \n",
      "Epoch 30/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5147     \n",
      "Epoch 31/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6924 - binary_accuracy: 0.5165     \n",
      "Epoch 32/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6924 - binary_accuracy: 0.5153     \n",
      "Epoch 33/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6921 - binary_accuracy: 0.5158     \n",
      "Epoch 34/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6925 - binary_accuracy: 0.5161     \n",
      "Epoch 35/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6924 - binary_accuracy: 0.5169     \n",
      "Epoch 36/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6925 - binary_accuracy: 0.5173     \n",
      "Epoch 37/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6924 - binary_accuracy: 0.5161     \n",
      "Epoch 38/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6924 - binary_accuracy: 0.5153     \n",
      "Epoch 39/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6926 - binary_accuracy: 0.5160     \n",
      "Epoch 40/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5168     \n",
      "Epoch 41/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6926 - binary_accuracy: 0.5174     \n",
      "Epoch 42/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6928 - binary_accuracy: 0.5166     \n",
      "Epoch 43/80\n",
      "154432/154432 [==============================] - 8s - loss: 0.6925 - binary_accuracy: 0.5166     \n",
      "Epoch 44/80\n",
      "154432/154432 [==============================] - 9s - loss: 0.6923 - binary_accuracy: 0.5175     \n",
      "152896/154432 [============================>.] - ETA: 0s403\n",
      "Epoch 1/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6942 - binary_accuracy: 0.5056    \n",
      "Epoch 2/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6929 - binary_accuracy: 0.5126    \n",
      "Epoch 3/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6927 - binary_accuracy: 0.5132    \n",
      "Epoch 4/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6927 - binary_accuracy: 0.5145    \n",
      "Epoch 5/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6924 - binary_accuracy: 0.5172    \n",
      "Epoch 6/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6926 - binary_accuracy: 0.5142    \n",
      "Epoch 7/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6925 - binary_accuracy: 0.5146    \n",
      "Epoch 8/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6924 - binary_accuracy: 0.5143    \n",
      "Epoch 9/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6924 - binary_accuracy: 0.5144    \n",
      "Epoch 10/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6923 - binary_accuracy: 0.5156    \n",
      "Epoch 11/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6923 - binary_accuracy: 0.5170    \n",
      "Epoch 12/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6922 - binary_accuracy: 0.5161    \n",
      "Epoch 13/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6920 - binary_accuracy: 0.5164    \n",
      "Epoch 14/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6923 - binary_accuracy: 0.5180    \n",
      "Epoch 15/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6919 - binary_accuracy: 0.5192    \n",
      "Epoch 16/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6920 - binary_accuracy: 0.5172    \n",
      "Epoch 17/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6919 - binary_accuracy: 0.5207    \n",
      "Epoch 18/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6917 - binary_accuracy: 0.5211    \n",
      "Epoch 19/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5225    \n",
      "Epoch 20/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6917 - binary_accuracy: 0.5209    \n",
      "Epoch 21/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6917 - binary_accuracy: 0.5220    \n",
      "Epoch 22/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6917 - binary_accuracy: 0.5212    \n",
      "Epoch 23/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6916 - binary_accuracy: 0.5227    \n",
      "Epoch 24/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5226    \n",
      "Epoch 25/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5222    \n",
      "Epoch 26/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5222    \n",
      "Epoch 27/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5220    \n",
      "Epoch 28/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6913 - binary_accuracy: 0.5233    \n",
      "Epoch 29/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5231    \n",
      "Epoch 30/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6917 - binary_accuracy: 0.5218    \n",
      "Epoch 31/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6916 - binary_accuracy: 0.5234    \n",
      "Epoch 32/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5222    \n",
      "Epoch 33/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6913 - binary_accuracy: 0.5240    \n",
      "Epoch 34/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5243    \n",
      "Epoch 35/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6914 - binary_accuracy: 0.5244    \n",
      "Epoch 36/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5241    \n",
      "Epoch 37/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5229    \n",
      "Epoch 38/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5250    \n",
      "Epoch 39/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5221    \n",
      "Epoch 40/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6915 - binary_accuracy: 0.5232    \n",
      "Epoch 41/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5268    \n",
      "Epoch 42/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6916 - binary_accuracy: 0.5247    \n",
      "Epoch 43/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5246    \n",
      "Epoch 44/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6914 - binary_accuracy: 0.5245    \n",
      "Epoch 45/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5264    \n",
      "Epoch 46/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6913 - binary_accuracy: 0.5234    \n",
      "Epoch 47/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5229    \n",
      "Epoch 48/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6909 - binary_accuracy: 0.5246    \n",
      "Epoch 49/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6913 - binary_accuracy: 0.5255    \n",
      "Epoch 50/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5260    \n",
      "Epoch 51/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6910 - binary_accuracy: 0.5264    \n",
      "Epoch 52/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6915 - binary_accuracy: 0.5244    \n",
      "Epoch 53/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6912 - binary_accuracy: 0.5249    \n",
      "Epoch 54/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6912 - binary_accuracy: 0.5245    \n",
      "Epoch 55/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6911 - binary_accuracy: 0.5248    \n",
      "Epoch 56/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5259    \n",
      "Epoch 57/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6909 - binary_accuracy: 0.5256    \n",
      "Epoch 58/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5273    \n",
      "Epoch 59/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5258    \n",
      "Epoch 60/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5273    \n",
      "Epoch 61/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5259    \n",
      "Epoch 62/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5263    \n",
      "Epoch 63/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5275    \n",
      "Epoch 64/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5258    \n",
      "Epoch 65/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6913 - binary_accuracy: 0.5261    \n",
      "Epoch 66/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6910 - binary_accuracy: 0.5269    \n",
      "Epoch 67/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6908 - binary_accuracy: 0.5268    \n",
      "Epoch 68/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6908 - binary_accuracy: 0.5276    \n",
      "Epoch 69/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6911 - binary_accuracy: 0.5269    \n",
      "Epoch 70/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6912 - binary_accuracy: 0.5254    \n",
      "Epoch 71/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6909 - binary_accuracy: 0.5277    \n",
      "Epoch 72/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5269    \n",
      "Epoch 73/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6909 - binary_accuracy: 0.5274    \n",
      "Epoch 74/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5272    \n",
      "Epoch 75/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5278    \n",
      "Epoch 76/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5279    \n",
      "Epoch 77/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6910 - binary_accuracy: 0.5274    \n",
      "Epoch 78/80\n",
      "204724/204724 [==============================] - 12s - loss: 0.6907 - binary_accuracy: 0.5271    \n",
      "Epoch 79/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6913 - binary_accuracy: 0.5291    \n",
      "Epoch 80/80\n",
      "204724/204724 [==============================] - 11s - loss: 0.6906 - binary_accuracy: 0.5294    \n",
      "203104/204724 [============================>.] - ETA: 0s446\n",
      "Epoch 1/80\n",
      "226568/226568 [==============================] - 14s - loss: 0.6932 - binary_accuracy: 0.5084    \n",
      "Epoch 2/80\n",
      "226568/226568 [==============================] - 12s - loss: 0.6930 - binary_accuracy: 0.5072    \n",
      "Epoch 3/80\n",
      "226568/226568 [==============================] - 13s - loss: 0.6929 - binary_accuracy: 0.5110    \n",
      "Epoch 4/80\n",
      "226568/226568 [==============================] - 13s - loss: 0.6926 - binary_accuracy: 0.5133    \n",
      "Epoch 5/80\n",
      "226568/226568 [==============================] - 13s - loss: 0.6927 - binary_accuracy: 0.5126    \n",
      "Epoch 6/80\n",
      "226568/226568 [==============================] - 13s - loss: 0.6924 - binary_accuracy: 0.5154    \n",
      "Epoch 7/80\n",
      "226568/226568 [==============================] - 13s - loss: 0.6924 - binary_accuracy: 0.5149    \n",
      "Epoch 8/80\n",
      "106368/226568 [=============>................] - ETA: 7s - loss: 0.6923 - binary_accuracy: 0.5184"
     ]
    }
   ],
   "source": [
    "returns_ann, dates_ann = get_return('ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a,b,v panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prices(returns, base):\n",
    "    # Converts returns into prices\n",
    "    s = [base]\n",
    "    for i in range(len(returns)):\n",
    "        s.append(base * (1 + returns[i]))\n",
    "    return np.array(s)\n",
    "\n",
    "def lpm(returns, threshold, order):\n",
    "    # This method returns a lower partial moment of the returns\n",
    "    # Create an array he same length as returns containing the minimum return threshold\n",
    "    threshold_array = np.empty(len(returns))\n",
    "    threshold_array.fill(threshold)\n",
    "    # Calculate the difference between the threshold and the returns\n",
    "    diff = threshold_array - returns\n",
    "    # Set the minimum of each to 0\n",
    "    diff = diff.clip(min=0)\n",
    "    # Return the sum of the different to the power of order\n",
    "    return np.sum(diff ** order) / len(returns)\n",
    "\n",
    "def var(returns, alpha):\n",
    "    # This method calculates the historical simulation var of the returns\n",
    "    sorted_returns = np.sort(returns)\n",
    "    # Calculate the index associated with alpha\n",
    "    index = int(alpha * len(sorted_returns))\n",
    "    # VaR should be positive\n",
    "    return abs(sorted_returns[index])\n",
    "def cvar(returns, alpha):\n",
    "    # This method calculates the condition VaR of the returns\n",
    "    sorted_returns = np.sort(returns)\n",
    "    # Calculate the index associated with alpha\n",
    "    index = int(alpha * len(sorted_returns))\n",
    "    # Calculate the total VaR beyond alpha\n",
    "    sum_var = sorted_returns[0]\n",
    "    for i in range(1, index):\n",
    "        sum_var += sorted_returns[i]\n",
    "    # Return the average VaR\n",
    "    # CVaR should be positive\n",
    "    return abs(sum_var / index)\n",
    "def sortino_ratio(er, returns, rf = 0, target=0):\n",
    "    return (er - rf) / math.sqrt(lpm(returns, target, 2))\n",
    "def dd(returns, tau):\n",
    "    # Returns the draw-down given time period tau\n",
    "    values = prices(returns, 100)\n",
    "    pos = len(values) - 1\n",
    "    pre = pos - tau\n",
    "    drawdown = float('+inf')\n",
    "    # Find the maximum drawdown given tau\n",
    "    while pre >= 0:\n",
    "        dd_i = (values[pos] / values[pre]) - 1\n",
    "        if dd_i < drawdown:\n",
    "            drawdown = dd_i\n",
    "        pos, pre = pos - 1, pre - 1\n",
    "    # Drawdown should be positive\n",
    "    return abs(drawdown)\n",
    "def max_dd(returns):\n",
    "    # Returns the maximum draw-down for any tau in (0, T) where T is the length of the return series\n",
    "    max_drawdown = float('-inf')\n",
    "    for i in range(0, len(returns)):\n",
    "        drawdown_i = dd(returns, i)\n",
    "        if drawdown_i > max_drawdown:\n",
    "            max_drawdown = drawdown_i\n",
    "    # Max draw-down should be positive\n",
    "    return abs(max_drawdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_a(returns):\n",
    "    df = pd.DataFrame(returns)\n",
    "    m = np.average(returns)\n",
    "    std = np.std(returns)\n",
    "    ste = std/np.sqrt(len(returns))\n",
    "    t_stat = m/ste\n",
    "    median = np.median(returns)\n",
    "    q1 = np.percentile(returns,25)\n",
    "    q3 = np.percentile(returns,75)\n",
    "    hit_ratio = len(np.array(returns)[np.array(returns) > 0] )/len(returns)\n",
    "    maximum = max(returns)\n",
    "    minimum = min(returns)\n",
    "    skew = df.skew()[0]\n",
    "    kurt = df.kurt()[0]\n",
    "    return [m,ste,t_stat,minimum,q1,median,q3,maximum,hit_ratio,std,skew,kurt]\n",
    "def get_stat_b(returns):\n",
    "    from scipy.stats import norm\n",
    "    VaR1 = var(returns, 0.01)\n",
    "    VaR5 = var(returns, 0.05)\n",
    "    CVaR1 = cvar(returns, 0.01)\n",
    "    CVaR5 = cvar(returns, 0.05)\n",
    "    return [VaR1, CVaR1, VaR5, CVaR5,max_dd(returns)]\n",
    "def get_stat_c(returns):\n",
    "    pa_returns, sharp_ratios = [], []\n",
    "    sortino_ratios, stds, dstds, ers = [],[],[],[]\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(returns):\n",
    "        annual_return = returns[i:i+250]\n",
    "        dstd = np.std(np.array(annual_return)[np.array(annual_return) < 0])\n",
    "        annual_profit = [i+1 for i in annual_return]\n",
    "        pa_return = np.array(annual_profit).cumprod()[-1]\n",
    "        m = np.average(annual_return)\n",
    "        std = np.std(annual_return)\n",
    "        sharp_ratio = (m*np.sqrt(250))/std\n",
    "        sortino_ratio = (m*np.sqrt(250))/dstd\n",
    "        sharp_ratios.append(sharp_ratio)\n",
    "        sortino_ratios.append(sortino_ratio)\n",
    "        stds.append(std)\n",
    "        dstds.append(dstd)\n",
    "        i+=250\n",
    "    return [np.average(pa_returns),np.average(stds),np.average(dstds), np.average(sharp_ratios),np.average(sortino_ratios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_a_1 = ['Mean return','Standard error','t-statistic','Minimum','Quartile 1','Median','Quartile 3']\n",
    "label_a_2 = ['Maximum','Share > 0','Standard dev.','Skewness','Kurtosis']\n",
    "label_a = label_a_1 + label_a_2\n",
    "panel_A = pd.DataFrame(index = label_a)\n",
    "dapan = get_price('399001.XSHE')['close']\n",
    "returns_mkt = ((dapan - dapan.shift(1))/dapan).dropna( how = 'any')\n",
    "panel_A['MKT'] = get_stat_a(returns_mkt)\n",
    "panel_A['RAF'] = get_stat_a(returns)\n",
    "panel_A['LOG'] = get_stat_a(returns_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel_A.to_csv('Panel A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_b = ['1-percent VaR','1-percent CVaR', '5-percent VaR','5-percent CVaR', 'Max Drawdown']\n",
    "panel_B = pd.DataFrame(index = label_b)\n",
    "panel_B['MKT'] = get_stat_b(returns_mkt)\n",
    "panel_B['RAF'] = get_stat_b(returns)\n",
    "panel_B['LOG'] = get_stat_b(returns_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "panel_B.to_csv('Panel B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/envs/Fintech/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/dell/anaconda3/envs/Fintech/lib/python3.5/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "label_c = ['p.a.Return', 'Standard Dev.','Downside Dev.','p.a.Sharpe ratio', 'p.a.Sortino ratio']\n",
    "panel_C= pd.DataFrame(index = label_c)\n",
    "panel_C['MKT'] = get_stat_c(returns_mkt)\n",
    "panel_C['RAF'] = get_stat_c(returns)\n",
    "panel_C['LOG'] = get_stat_c(returns_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "panel_C.to_csv(\"Panel C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dapan = get_price('399001.XSHE')['close']\n",
    "returns = ((dapan - dapan.shift(1))/dapan).dropna( how = 'any')\n",
    "df = pd.DataFrame(returns)\n",
    "m = np.average(returns)\n",
    "std = np.std(returns)\n",
    "ste = std/np.sqrt(len(returns))\n",
    "t_stat = m/ste\n",
    "median = np.median(returns)\n",
    "q1 = np.percentile(returns,25)\n",
    "q3 = np.percentile(returns,75)\n",
    "hit_ratio = len(np.array(returns)[np.array(returns) > 0] )/len(returns)\n",
    "maximum = max(returns)\n",
    "minimum = min(returns)\n",
    "skew = df.skew()[0]\n",
    "kurt = df.kurt()[0]\n",
    "log_stats_a = [m,ste,t_stat,minimum,q1,median,q3,maximum,hit_ratio,std,skew,kurt]\n",
    "label_a_1 = ['Mean return','Standard error','t-statistic','Minimum','Quartile 1','Median','Quartile 3']\n",
    "label_a_2 = ['Maximum','Share > 0','Standard dev.','Skewness','Kurtosis']\n",
    "label_a = label_a_1 + label_a_2\n",
    "panel_A = pd.DataFrame(index = label_a)\n",
    "panel_A['MKT'] = log_stats_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>RAF</th>\n",
       "      <th>LOG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean return</th>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.011438</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard error</th>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t-statistic</th>\n",
       "      <td>-0.666569</td>\n",
       "      <td>19.939605</td>\n",
       "      <td>0.407662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum</th>\n",
       "      <td>-0.072152</td>\n",
       "      <td>-0.110824</td>\n",
       "      <td>-0.111106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quartile 1</th>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>-0.012391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>-0.000715</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quartile 3</th>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.028010</td>\n",
       "      <td>0.015672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum</th>\n",
       "      <td>0.040749</td>\n",
       "      <td>0.091170</td>\n",
       "      <td>0.151264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Share &gt; 0</th>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>0.537751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard dev.</th>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.026598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>-0.563184</td>\n",
       "      <td>-0.176974</td>\n",
       "      <td>-0.573629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>2.809978</td>\n",
       "      <td>1.105529</td>\n",
       "      <td>2.270824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MKT        RAF       LOG\n",
       "Mean return    -0.000628   0.011438  0.000217\n",
       "Standard error  0.000942   0.000574  0.000533\n",
       "t-statistic    -0.666569  19.939605  0.407662\n",
       "Minimum        -0.072152  -0.110824 -0.111106\n",
       "Quartile 1     -0.007417  -0.004841 -0.012391\n",
       "Median         -0.000715   0.011524  0.002041\n",
       "Quartile 3      0.006765   0.028010  0.015672\n",
       "Maximum         0.040749   0.091170  0.151264\n",
       "Share > 0       0.485356   0.683936  0.537751\n",
       "Standard dev.   0.014568   0.028623  0.026598\n",
       "Skewness       -0.563184  -0.176974 -0.573629\n",
       "Kurtosis        2.809978   1.105529  2.270824"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>RAF</th>\n",
       "      <th>LOG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p.a.Return</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Dev.</th>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.026187</td>\n",
       "      <td>0.025160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downside Dev.</th>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.017754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p.a.Sharpe ratio</th>\n",
       "      <td>-0.681736</td>\n",
       "      <td>6.804771</td>\n",
       "      <td>0.526319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p.a.Sortino ratio</th>\n",
       "      <td>-0.914701</td>\n",
       "      <td>11.860618</td>\n",
       "      <td>0.784132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MKT        RAF       LOG\n",
       "p.a.Return              NaN        NaN       NaN\n",
       "Standard Dev.      0.014568   0.026187  0.025160\n",
       "Downside Dev.      0.010857   0.016620  0.017754\n",
       "p.a.Sharpe ratio  -0.681736   6.804771  0.526319\n",
       "p.a.Sortino ratio -0.914701  11.860618  0.784132"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MKT</th>\n",
       "      <th>RAF</th>\n",
       "      <th>LOG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-percent VaR</th>\n",
       "      <td>0.039275</td>\n",
       "      <td>0.069747</td>\n",
       "      <td>0.088732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-percent CVaR</th>\n",
       "      <td>0.063997</td>\n",
       "      <td>0.084120</td>\n",
       "      <td>0.096230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-percent VaR</th>\n",
       "      <td>0.025204</td>\n",
       "      <td>0.035728</td>\n",
       "      <td>0.045049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-percent CVaR</th>\n",
       "      <td>0.036361</td>\n",
       "      <td>0.054918</td>\n",
       "      <td>0.069078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>0.100961</td>\n",
       "      <td>0.185056</td>\n",
       "      <td>0.227898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MKT       RAF       LOG\n",
       "1-percent VaR   0.039275  0.069747  0.088732\n",
       "1-percent CVaR  0.063997  0.084120  0.096230\n",
       "5-percent VaR   0.025204  0.035728  0.045049\n",
       "5-percent CVaR  0.036361  0.054918  0.069078\n",
       "Max Drawdown    0.100961  0.185056  0.227898"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python(Fintech)",
   "language": "python",
   "name": "fintech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
